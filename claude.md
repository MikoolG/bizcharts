# BizCharts

4chan /biz/ sentiment analysis platform producing Fear/Greed indices and per-coin sentiment tracking.

## Current Status (Dec 2024)

| Component | Status | Notes |
|-----------|--------|-------|
| Live Scraper | âœ… Tested | Pulls ~150 threads from 4chan catalog, downloads thumbnails |
| Warosu Importer | âœ… Tested | Fixed timestamp parsing, captures OPs only (not replies) |
| Labeling GUI | âœ… Tested | 200 posts labeled (180 live, 20 warosu), avg sentiment ~2.4 (bearish) |
| Text Sentiment | ğŸ”„ Pending | VADER + lexicon implementation |
| Image Sentiment | ğŸ”„ Pending | CLIP/color analysis |
| Dashboard | ğŸ”„ Pending | Streamlit UI |

## Architecture

**OP-focused design**: Scrapes catalog only (not individual threads). One catalog request = ~150 thread OPs with full text, images, and engagement metrics.

```
Data Collection (Rust)              Analysis (Python)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Live Scraper        â”‚            â”‚ Text: VADER+lexicon â”‚
â”‚ - catalog.json/60s  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Image: Color/CLIP   â”‚
â”‚ - 1 req/sec limit   â”‚  SQLite    â”‚ Fusion: 60/40 split â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  (shared)  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Warosu Importer     â”‚            â”‚ Manual Labeling UI  â”‚
â”‚ - Historical data   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Analysis/Export     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Maintenance         â”‚            â”‚ Price Provider      â”‚
â”‚ - Retention/cleanup â”‚            â”‚ - Multi-source API  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Project Structure

```
bizcharts/
â”œâ”€â”€ rust-scraper/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ main.rs          # CLI entry (--warosu, --maintain, --stats)
â”‚       â”œâ”€â”€ scraper.rs       # Live catalog scraper
â”‚       â”œâ”€â”€ warosu.rs        # Historical archive importer
â”‚       â”œâ”€â”€ db.rs            # SQLite schema + operations
â”‚       â”œâ”€â”€ extractor.rs     # Coin ticker extraction
â”‚       â””â”€â”€ maintenance.rs   # Retention policies, cleanup
â”œâ”€â”€ python-ml/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ text_analyzer.py   # VADER + custom lexicon
â”‚       â”œâ”€â”€ image_analyzer.py  # CLIP + color analysis
â”‚       â”œâ”€â”€ aggregator.py      # Sentiment fusion
â”‚       â”œâ”€â”€ price_provider.py  # CoinGecko/Binance/CMC rotation
â”‚       â”œâ”€â”€ labeler.py         # Manual labeling GUI (Tkinter)
â”‚       â”œâ”€â”€ label_analysis.py  # Training data analysis/export
â”‚       â””â”€â”€ dashboard.py       # Streamlit UI
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.toml        # All configuration
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ sentiment-strategy.md  # Analysis approach
â”‚   â””â”€â”€ labeling-guide.md      # Manual labeling process
â””â”€â”€ data/                      # Databases (gitignored)
    â””â”€â”€ posts.db
```

## CLI Usage

```bash
# Live catalog scraping
cargo run -- --live --once    # Single snapshot of current catalog (~150 threads)
cargo run -- --live           # Continuous polling (every 60s)

# Import historical data from Warosu archive
cargo run -- --warosu --search bitcoin --max 1000
cargo run -- --warosu --from 2024-01-01 --to 2024-12-31
cargo run -- --warosu --pages 10          # Browse N pages of general activity

# Incremental imports (avoids duplicates)
cargo run -- --coverage                   # Show data coverage report
cargo run -- --warosu --continue          # Import from last date forward
cargo run -- --warosu --backfill          # Import older data before earliest

# Database maintenance
cargo run -- --stats      # Show storage statistics
cargo run -- --maintain   # Run cleanup (strips old HTML, aggregates snapshots)

# Manual labeling (Python)
cd python-ml
python3 -m src.labeler                              # Start labeling UI
python3 -m src.labeler --source live                # Label only live catalog data
python3 -m src.labeler --source warosu              # Label only Warosu data
python3 -m src.labeler --from 2024-01-01            # Label from date onward
python3 -m src.labeler --stats                      # Show labeling statistics
python3 -m src.labeler --export labels.csv          # Export to CSV
```

## Database Schema

Primary table: `thread_ops` (one row per thread OP)

```sql
thread_ops (
    thread_id INTEGER PRIMARY KEY,
    subject TEXT,
    op_text TEXT,                    -- Raw HTML
    op_text_clean TEXT,              -- Stripped for analysis
    reply_count INTEGER,             -- Engagement weight
    image_url TEXT,
    sentiment_score REAL,            -- -1 to +1
    sentiment_confidence REAL,       -- 0 to 1
    source TEXT                      -- 'live' or 'warosu'
)

coin_mentions (thread_id, coin_symbol, confidence, mention_source)
training_labels (thread_id, sentiment_rating 1-5, labeler_id)  -- 1=bearish, 3=neutral, 5=bullish
catalog_snapshots (snapshot_at, total_threads, avg_reply_count, top_coins)
```

## Sentiment Strategy

See [docs/sentiment-strategy.md](docs/sentiment-strategy.md) for full details.

**Key concepts:**
- **Multi-signal fusion**: Text (60%) + Image (40%) sentiment
- **Confidence weighting**: Uncertain posts get less weight in aggregations
- **Reply-based importance**: Popular threads (high reply count) influence aggregate more
- **Color heuristics**: Red-dominant images = bearish, green = bullish (before ML)

**Lexicon examples** (VADER additions):
- WAGMI: +3.5, NGMI: -3.5, LFG: +3.0
- "we're so back": +2.5, "it's over": -3.5
- moon/mooning: +3.0, rekt: -3.5

## Storage & Retention

Default retention (configurable in `maintenance.rs`):
- **Full HTML**: 30 days (then stripped, keep clean text)
- **Thread metadata**: 1 year
- **Catalog snapshots**: Full 7d â†’ Hourly 90d â†’ Daily thereafter
- **Popular threads (50+ replies)**: Preserved indefinitely
- **Training labels**: Never deleted

Run `biz-scraper --maintain` periodically to apply retention policies.

## Price Data

Multi-source rotation to stay within free tier limits:
1. **CoinGecko** - 10k calls/month free
2. **Binance** - Unlimited public API
3. **CoinMarketCap** - 10k calls/month free (needs API key)

Configure in `settings.toml` under `[price_data]`.

## Development

```bash
# Build Rust scraper
cd rust-scraper && cargo build --release

# Setup Python
cd python-ml
python -m venv .venv && source .venv/bin/activate
pip install -e .

# Run tests
cargo test                    # Rust
pytest                        # Python
```

## API Reference

**4chan API** (1 req/sec max):
```
GET https://a.4cdn.org/biz/catalog.json  # All thread OPs
GET https://i.4cdn.org/biz/{tim}{ext}    # Full image
GET https://i.4cdn.org/biz/{tim}s.jpg    # Thumbnail
```

**Warosu Archive** (1 req/2sec recommended):
```
https://warosu.org/biz/?task=search&search_subject=bitcoin
```

## Key Files

| File | Purpose |
|------|---------|
| [rust-scraper/src/db.rs](rust-scraper/src/db.rs) | Database schema and all SQL |
| [docs/sentiment-strategy.md](docs/sentiment-strategy.md) | Full sentiment analysis approach |
| [docs/labeling-guide.md](docs/labeling-guide.md) | Manual labeling instructions |
| [config/settings.toml](config/settings.toml) | All configuration options |
